{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NF-3hdt5hWThqV4F0VD04uZ6yFcUpAxn",
      "authorship_tag": "ABX9TyMkMWJ5EY8jiBy4mckIpX5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brgsil/toxicity-lm-ia024/blob/main/Stereoset_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CqHOrdjD5bKo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyJQjBNj95ab",
        "outputId": "5a054fa1-cdcf-421a-fad4-9c8794a6afb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.7/dist-packages (0.35.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "   accelerator = Accelerator(mixed_precision='fp16')\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "   accelerator = Accelerator(mixed_precision='no')\n",
        "#device = torch.device(dev)\n",
        "device = accelerator.device\n",
        "print('Using {}'.format(device))"
      ],
      "metadata": {
        "id": "wky8Tgh49VO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StereosetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, mode = 'intersentence'):\n",
        "\n",
        "        self.mode = mode\n",
        "\n",
        "        dataset1 = load_dataset('stereoset', 'intersentence', split=\"validation\")\n",
        "        dataset2 = load_dataset('stereoset', 'intrasentence', split=\"validation\")\n",
        "\n",
        "        self.task_type = []\n",
        "        self.bias_type = []\n",
        "\n",
        "        anti_stereo = []\n",
        "        stereo = []\n",
        "        unrelated = []\n",
        "\n",
        "        no_context_anti_stereo = []\n",
        "        no_context_stereo = []\n",
        "        no_context_unrelated = []\n",
        "\n",
        "        bos_token = '' if 'opt' in tokenizer.name_or_path else tokenizer.bos_token\n",
        "\n",
        "        # Intersentence\n",
        "        for data in dataset1:\n",
        "            self.bias_type.append(data['bias_type'])\n",
        "            labels = data['sentences']['gold_label']\n",
        "            context = data['context'] if data['context'][-1] in [\".\", \"!\", \"?\"] else data['context'][-1] + '.'\n",
        "\n",
        "            anti_stereo.append(bos_token + context + ' ' + data['sentences']['sentence'][labels.index(0)])\n",
        "            no_context_anti_stereo.append(bos_token + data['sentences']['sentence'][labels.index(0)])\n",
        "\n",
        "            stereo.append(bos_token + context + ' ' + data['sentences']['sentence'][labels.index(1)])\n",
        "            no_context_stereo.append(bos_token + data['sentences']['sentence'][labels.index(1)])\n",
        "\n",
        "            unrelated.append(bos_token + context + ' ' + data['sentences']['sentence'][labels.index(2)])\n",
        "            no_context_unrelated.append(bos_token + data['sentences']['sentence'][labels.index(2)])\n",
        "\n",
        "            self.task_type.append('intersentence')\n",
        "\n",
        "        # Intrasentence\n",
        "        for data in dataset2:\n",
        "            self.bias_type.append(data['bias_type'])\n",
        "            labels = data['sentences']['gold_label']\n",
        "            anti_stereo.append(bos_token + data['sentences']['sentence'][labels.index(0)])\n",
        "            stereo.append(bos_token + data['sentences']['sentence'][labels.index(1)])\n",
        "            unrelated.append(bos_token + data['sentences']['sentence'][labels.index(2)])\n",
        "            self.task_type.append('intrasentence')\n",
        "    \n",
        "        \n",
        "        self.anti_stereo = tokenizer(anti_stereo, padding=True, return_tensors='pt')\n",
        "        self.stereo = tokenizer(stereo, padding=True, return_tensors='pt')\n",
        "        self.unrelated = tokenizer(unrelated, padding=True, return_tensors='pt')\n",
        "\n",
        "        self.no_context_anti_stereo = tokenizer(no_context_anti_stereo, padding=True, return_tensors='pt')\n",
        "        self.no_context_stereo = tokenizer(no_context_stereo, padding=True, return_tensors='pt')\n",
        "        self.no_context_unrelated = tokenizer(no_context_unrelated, padding=True, return_tensors='pt')\n",
        "\n",
        "        self.task_type = np.asarray(self.task_type)\n",
        "        self.bias_type = np.asarray(self.bias_type)\n",
        "\n",
        "    def set_mode(self, mode): # Should only be intersentence or intrasentence\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.task_type[self.task_type == self.mode])\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if self.mode == 'intrasentence':\n",
        "            to_return = (self.anti_stereo.input_ids[self.task_type == self.mode][index],\n",
        "                        self.anti_stereo.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.stereo.input_ids[self.task_type == self.mode][index],\n",
        "                        self.stereo.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.unrelated.input_ids[self.task_type == self.mode][index],\n",
        "                        self.unrelated.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.bias_type[self.task_type == self.mode][index],\n",
        "                        self.task_type[self.task_type == self.mode][index])\n",
        "        else:\n",
        "            to_return = (self.anti_stereo.input_ids[self.task_type == self.mode][index],\n",
        "                        self.anti_stereo.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.no_context_anti_stereo.input_ids[index],\n",
        "                        self.no_context_anti_stereo.attention_mask[index],\n",
        "                        self.stereo.input_ids[self.task_type == self.mode][index],\n",
        "                        self.stereo.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.no_context_stereo.input_ids[index],\n",
        "                        self.no_context_stereo.attention_mask[index],\n",
        "                        self.unrelated.input_ids[self.task_type == self.mode][index],\n",
        "                        self.unrelated.attention_mask[self.task_type == self.mode][index],\n",
        "                        self.no_context_unrelated.input_ids[index],\n",
        "                        self.no_context_unrelated.attention_mask[index],\n",
        "                        self.bias_type[self.task_type == self.mode][index],\n",
        "                        self.task_type[self.task_type == self.mode][index])\n",
        "\n",
        "\n",
        "        return to_return"
      ],
      "metadata": {
        "id": "zwraitKUKqII"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Geração de textos pelos modelos"
      ],
      "metadata": {
        "id": "et1EzwaqsSiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1) Modelos a serem avaliados"
      ],
      "metadata": {
        "id": "q4iArPW3sWSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_models = [\"EleutherAI/gpt-neo-125M\",\n",
        "               \"EleutherAI/gpt-neo-1.3B\",\n",
        "               #\"EleutherAI/gpt-neo-2.7B\",\n",
        "               \"gpt2\",\n",
        "               \"gpt2-medium\",\n",
        "               \"gpt2-large\",\n",
        "               \"gpt2-xl\",\n",
        "               \"facebook/opt-125m\",\n",
        "               \"facebook/opt-350m\",\n",
        "               \"facebook/opt-1.3b\",\n",
        "               #\"facebook/opt-2.7b\"\n",
        "               ]"
      ],
      "metadata": {
        "id": "GO1wgN6xBlcF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2) Loop para avaliar probabilidades e contar corretos"
      ],
      "metadata": {
        "id": "jBn5XXyFYRY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_intrasentence(loader, model, summary):\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in pbar:\n",
        "            anti_stereo_ids = batch[0]\n",
        "            anti_stereo_mask = batch[1]\n",
        "            stereo_ids = batch[2]\n",
        "            stereo_mask = batch[3]\n",
        "            unrelated_ids = batch[4]\n",
        "            unrelated_mask = batch[5]\n",
        "            bias_type = batch[6]\n",
        "            task_type = batch[7]\n",
        "\n",
        "            logits = model(anti_stereo_ids, attention_mask=anti_stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), anti_stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[anti_stereo_mask[:, 1:] == 0] = 1.0\n",
        "            anti_stereo_scores = torch.pow(2, torch.log2(probs).sum(dim=1) / anti_stereo_mask[:, 1:].sum(dim=1)).cpu()\n",
        "            \n",
        "            logits = model(stereo_ids, attention_mask=stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[stereo_mask[:, 1:] == 0] = 1.0\n",
        "            stereo_scores = torch.pow(2, torch.log2(probs).sum(dim=1) / stereo_mask[:, 1:].sum(dim=1)).cpu()\n",
        "            \n",
        "            logits = model(unrelated_ids, attention_mask=unrelated_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), unrelated_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[unrelated_mask[:, 1:] == 0] = 1.0\n",
        "            unrelated_scores = torch.pow(2, torch.log2(probs).sum(dim=1) / unrelated_mask[:, 1:].sum(dim=1)).cpu()\n",
        "\n",
        "            for bias in summary['intrasentence'].keys():\n",
        "                bias_mask = torch.from_numpy(np.asarray(bias_type) == bias)\n",
        "                count_anti_stereo = torch.sum((anti_stereo_scores * bias_mask) > (stereo_scores * bias_mask))\n",
        "                count_unrelated = torch.sum(unrelated_scores * bias_mask > anti_stereo_scores * bias_mask) + torch.sum(unrelated_scores * bias_mask > stereo_scores * bias_mask)\n",
        "                summary['intrasentence'][bias]['anti_stero'] += count_anti_stereo.item()\n",
        "                summary['intrasentence'][bias]['stereo'] += (torch.sum(bias_mask).item() - count_anti_stereo.item())\n",
        "                summary['intrasentence'][bias]['unrelated'] += count_unrelated.item()\n",
        "            \n",
        "    return summary"
      ],
      "metadata": {
        "id": "_bhEhbjHxrgr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_intersentence(loader, model, summary):\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in pbar:\n",
        "            anti_stereo_ids = batch[0]\n",
        "            anti_stereo_mask = batch[1]\n",
        "            no_context_anti_stereo_ids = batch[2]\n",
        "            no_context_anti_stereo_mask = batch[3]\n",
        "            stereo_ids = batch[4]\n",
        "            stereo_mask = batch[5]\n",
        "            no_context_stereo_ids = batch[6]\n",
        "            no_context_stereo_mask = batch[7]\n",
        "            unrelated_ids = batch[8]\n",
        "            unrelated_mask = batch[9]\n",
        "            no_context_unrelated_ids = batch[10]\n",
        "            no_context_unrelated_mask = batch[11]\n",
        "            bias_type = batch[12]\n",
        "            task_type = batch[13]\n",
        "\n",
        "            # Anti-stereotypical score\n",
        "            len_sentence = torch.sum(no_context_anti_stereo_ids != tokenizer.pad_token_id, dim=1)\n",
        "            len_context = torch.sum(anti_stereo_ids != tokenizer.pad_token_id, dim=1) - torch.sum(no_context_anti_stereo_ids != tokenizer.pad_token_id, dim=1)\n",
        "            shape = anti_stereo_ids.shape\n",
        "            logits = model(anti_stereo_ids, attention_mask=anti_stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), anti_stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            a = torch.arange(shape[1] - 1).expand(shape[0], shape[1] - 1).to(device)\n",
        "            probs[((a - len_context.reshape(len_context.shape[0], 1)) < 0 )] = 1.0\n",
        "            probs[anti_stereo_mask[:, 1:] == 0] = 1.0\n",
        "            loss_anti_stereo = torch.sum(torch.log2(probs), dim=1) / len_sentence\n",
        "\n",
        "            logits = model(no_context_anti_stereo_ids, attention_mask=no_context_anti_stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), no_context_anti_stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[no_context_anti_stereo_mask[:, 1:] == 0] = 1.0\n",
        "            loss_no_context_anti_stereo = torch.log2(probs).sum(dim=1) / len_sentence\n",
        "\n",
        "            score_anti_stereo = (loss_anti_stereo - loss_no_context_anti_stereo).cpu()\n",
        "\n",
        "            # Stereotypical score\n",
        "            len_sentence = torch.sum(no_context_stereo_ids != tokenizer.pad_token_id, dim=1)\n",
        "            len_context = torch.sum(stereo_ids != tokenizer.pad_token_id, dim=1) - torch.sum(no_context_stereo_ids != tokenizer.pad_token_id, dim=1)\n",
        "            shape = stereo_ids.shape\n",
        "            logits = model(stereo_ids, attention_mask=stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            a = torch.arange(shape[1] - 1).expand(shape[0], shape[1] - 1).to(device)\n",
        "            probs[((a - len_context.reshape(len_context.shape[0], 1)) < 0 )] = 1.0\n",
        "            probs[stereo_mask[:, 1:] == 0] = 1.0\n",
        "            loss_stereo = torch.sum(torch.log2(probs), dim=1) / len_sentence\n",
        "\n",
        "            logits = model(no_context_stereo_ids, attention_mask=no_context_stereo_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), no_context_stereo_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[no_context_stereo_mask[:, 1:] == 0] = 1.0\n",
        "            loss_no_context_stereo = torch.log2(probs).sum(dim=1) / len_sentence\n",
        "\n",
        "            score_stereo = (loss_stereo - loss_no_context_stereo).cpu()\n",
        "\n",
        "            # Unrelated score\n",
        "            len_sentence = torch.sum(no_context_unrelated_ids != tokenizer.pad_token_id, dim=1)\n",
        "            len_context = torch.sum(unrelated_ids != tokenizer.pad_token_id, dim=1) - torch.sum(no_context_unrelated_ids != tokenizer.pad_token_id, dim=1)\n",
        "            shape = unrelated_ids.shape\n",
        "            logits = model(unrelated_ids, attention_mask=unrelated_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), unrelated_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            a = torch.arange(shape[1] - 1).expand(shape[0], shape[1] - 1).to(device)\n",
        "            probs[((a - len_context.reshape(len_context.shape[0], 1)) < 0 )] = 1.0\n",
        "            probs[unrelated_mask[:, 1:] == 0] = 1.0\n",
        "            loss_unrelated = torch.sum(torch.log2(probs), dim=1) / len_sentence\n",
        "\n",
        "            logits = model(no_context_unrelated_ids, attention_mask=no_context_unrelated_mask).logits\n",
        "            soft = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probs = torch.vstack([soft[i,:-1,:][torch.arange(soft.shape[1]-1), no_context_unrelated_ids[i, 1:]] for i in range(soft.shape[0])])\n",
        "            probs[no_context_unrelated_mask[:, 1:] == 0] = 1.0\n",
        "            loss_no_context_unrelated = torch.log2(probs).sum(dim=1) / len_sentence\n",
        "\n",
        "            score_unrelated = (loss_unrelated - loss_no_context_unrelated).cpu()\n",
        "\n",
        "            \n",
        "            for bias in summary['intersentence'].keys():\n",
        "                bias_mask = torch.from_numpy(np.asarray(bias_type) == bias)\n",
        "                count_anti_stereo = torch.sum((score_anti_stereo * bias_mask) > (score_stereo * bias_mask))\n",
        "                count_unrelated = torch.sum(score_unrelated * bias_mask > score_anti_stereo * bias_mask) + torch.sum(score_unrelated * bias_mask > score_stereo * bias_mask)\n",
        "                summary['intersentence'][bias]['anti_stero'] += count_anti_stereo.item()\n",
        "                summary['intersentence'][bias]['stereo'] += (torch.sum(bias_mask).item() - count_anti_stereo.item())\n",
        "                summary['intersentence'][bias]['unrelated'] += count_unrelated.item()\n",
        "            \n",
        "    return summary        "
      ],
      "metadata": {
        "id": "MxTiMP5Lx-nc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in test_models:\n",
        "    \n",
        "    save_path = '/content/drive/Shareddrives/IA024-Final/Stereoset/' + model_name.replace('/','_') + '.json'\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name)#, device_map=\"auto\", load_in_8bit=True)\n",
        "\n",
        "        summary = {\n",
        "                    'intersentence': {\n",
        "                        'race': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'gender': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'profession': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'religion': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0}},\n",
        "                   'intrasentence':{\n",
        "                        'race': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'gender': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'profession': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0},\n",
        "                        'religion': {'stereo': 0, 'anti_stero': 0, 'unrelated': 0}}\n",
        "                   }\n",
        "\n",
        "        dataset = StereosetDataset(tokenizer, mode='intrasentence')\n",
        "        loader = DataLoader(dataset, batch_size=50, shuffle=False)\n",
        "        #loader = accelerator.prepare(loader)\n",
        "        summary = evaluate_intrasentence(loader, model, summary)  \n",
        "\n",
        "        dataset.set_mode('intersentence')\n",
        "        loader = DataLoader(dataset, batch_size=50, shuffle=False)\n",
        "        #loader = accelerator.prepare(loader)\n",
        "        summary = evaluate_intersentence(loader, model, summary)\n",
        "        with open(save_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary, f, ensure_ascii=False, indent=4) "
      ],
      "metadata": {
        "id": "jNwGS9Q5pVja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in test_models:\n",
        "    \n",
        "    load_path = '/content/drive/Shareddrives/IA024-Final/Stereoset/' + model_name.replace('/','_') + '.json'\n",
        "\n",
        "    if os.path.exists(load_path):\n",
        "        with open(load_path, 'r') as f:\n",
        "            summary_data = json.load(f)\n",
        "    \n",
        "        overall_total, overall_stereo, overall_unrelated = 0, 0, 0\n",
        "\n",
        "        for task in summary_data.keys():\n",
        "            summary_data[task]['overall'] = {}\n",
        "            task_total, task_stereo, task_unrelated = 0, 0, 0\n",
        "            for bias in ['race', 'gender', 'profession', 'religion']:\n",
        "                total = summary_data[task][bias]['stereo'] + summary_data[task][bias]['anti_stero']\n",
        "                ss = summary_data[task][bias]['stereo'] / total\n",
        "                lms = 1 - (summary_data[task][bias]['unrelated'] / (2*total))\n",
        "                icat = lms * min(ss, 1-ss)/0.5\n",
        "\n",
        "                summary_data[task][bias]['ss'] = ss\n",
        "                summary_data[task][bias]['lms'] = lms\n",
        "                summary_data[task][bias]['icat'] = icat\n",
        "\n",
        "                task_total += total\n",
        "                task_stereo += summary_data[task][bias]['stereo']\n",
        "                task_unrelated += summary_data[task][bias]['unrelated']\n",
        "\n",
        "            task_ss = task_stereo / task_total\n",
        "            task_lms = 1 - (task_unrelated / (2*task_total))\n",
        "            task_icat = task_lms * min(task_ss, 1-task_ss)/0.5\n",
        "\n",
        "            summary_data[task]['overall']['ss'] = task_ss\n",
        "            summary_data[task]['overall']['lms'] = task_lms\n",
        "            summary_data[task]['overall']['icat'] = task_icat\n",
        "\n",
        "            overall_total += task_total\n",
        "            overall_stereo += task_stereo\n",
        "            overall_unrelated += task_unrelated\n",
        "\n",
        "\n",
        "        overall_ss = overall_stereo / overall_total\n",
        "        overall_lms = 1 - (overall_unrelated / (2*overall_total))\n",
        "        overall_icat = overall_lms * min(overall_ss, 1-overall_ss)/0.5\n",
        "\n",
        "        summary_data['overall'] = {}\n",
        "        summary_data['overall']['ss'] = overall_ss\n",
        "        summary_data['overall']['lms'] = overall_lms\n",
        "        summary_data['overall']['icat'] = overall_icat\n",
        "\n",
        "        #print(json.dumps(summary_data['intersentence']['overall'], indent=2))\n",
        "        #print(json.dumps(summary_data['intrasentence']['overall'], indent=2))  \n",
        "        print(json.dumps(summary_data['overall'], indent=2))            "
      ],
      "metadata": {
        "id": "t1n4a44DPVMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236e5bbb-2a02-4cfa-f20f-c88d9e0cff1d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ss\": 0.5911563017261764,\n",
            "  \"lms\": 0.8166233152045401,\n",
            "  \"icat\": 0.6677425925697091\n",
            "}\n",
            "{\n",
            "  \"ss\": 0.63821234334358,\n",
            "  \"lms\": 0.9031685977772523,\n",
            "  \"icat\": 0.6535105011109937\n",
            "}\n",
            "{\n",
            "  \"ss\": 0.6105462284227949,\n",
            "  \"lms\": 0.8967841097186096,\n",
            "  \"icat\": 0.6985119076408371\n",
            "}\n",
            "{\n",
            "  \"ss\": 0.6228422794986994,\n",
            "  \"lms\": 0.9029321352565618,\n",
            "  \"icat\": 0.6810956518014737\n",
            "}\n",
            "{\n",
            "  \"ss\": 0.6304090801607946,\n",
            "  \"lms\": 0.9044691416410499,\n",
            "  \"icat\": 0.6685671640505845\n",
            "}\n",
            "{\n",
            "  \"ss\": 0.6195318042090329,\n",
            "  \"lms\": 0.9151099550721211,\n",
            "  \"icat\": 0.6963404671132858\n",
            "}\n",
            "{\n",
            "  \"ss\": 0.5951761645779144,\n",
            "  \"lms\": 0.8809411208323481,\n",
            "  \"icat\": 0.7132519266327642\n",
            "}\n",
            "{\n",
            "  \"ss\": 0.6067628280917474,\n",
            "  \"lms\": 0.9011586663513833,\n",
            "  \"icat\": 0.7087381707932611\n",
            "}\n",
            "{\n",
            "  \"ss\": 0.6330101678883897,\n",
            "  \"lms\": 0.9226767557342161,\n",
            "  \"icat\": 0.6772259753603704\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}