{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LwKmHu5SEFkUXBPIpJA46uQBOqqDOEHt",
      "authorship_tag": "ABX9TyNLEmbhF58V0THp1y5EISEc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d112fa02f5c043dbad43719875b3c062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_011ad6dd845548388bb76c3fd974060c",
              "IPY_MODEL_7a0e60576f844f5492726c605fcfb7da",
              "IPY_MODEL_9d4b78a0e4b944208f1607c4aff5b2a2"
            ],
            "layout": "IPY_MODEL_2e9c30d6945e45da89f2c6a18e7981ba"
          }
        },
        "011ad6dd845548388bb76c3fd974060c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf96fd2359747318f256775b7e4d43a",
            "placeholder": "​",
            "style": "IPY_MODEL_7e64e6581e1b4e95a6e4219d6eba6c49",
            "value": "100%"
          }
        },
        "7a0e60576f844f5492726c605fcfb7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dc57ccb43b74418945528774860471f",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3663b7c172094c4f9982909718631f86",
            "value": 50
          }
        },
        "9d4b78a0e4b944208f1607c4aff5b2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b1f67058e54407ae80d9ab054c2971",
            "placeholder": "​",
            "style": "IPY_MODEL_928841920bcb4796a8db48a02ffe74e3",
            "value": " 50/50 [00:19&lt;00:00,  2.84it/s, Save Time=0.00484]"
          }
        },
        "2e9c30d6945e45da89f2c6a18e7981ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf96fd2359747318f256775b7e4d43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e64e6581e1b4e95a6e4219d6eba6c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dc57ccb43b74418945528774860471f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3663b7c172094c4f9982909718631f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4b1f67058e54407ae80d9ab054c2971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "928841920bcb4796a8db48a02ffe74e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "793da7d00b934211b0a9e3ebf838f4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab81245a6d41463eb136c1bec5685ecf",
              "IPY_MODEL_61d8f5bf131a480d91eb45595529941f",
              "IPY_MODEL_e71ee40d8d4c4407bd28edaa9462d0a7"
            ],
            "layout": "IPY_MODEL_09266c6f9db14c51b15caaf120ba8e6d"
          }
        },
        "ab81245a6d41463eb136c1bec5685ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53ebcbf3c674bffb05a2c2c6d5fb8f6",
            "placeholder": "​",
            "style": "IPY_MODEL_b23b211a494d46578512e994a75ca6f7",
            "value": "100%"
          }
        },
        "61d8f5bf131a480d91eb45595529941f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2015359409a7460ea04a537987b57a44",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aee02b416d7f422db9940e19074f250a",
            "value": 50
          }
        },
        "e71ee40d8d4c4407bd28edaa9462d0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c897976afd564098b807edf49fcfbace",
            "placeholder": "​",
            "style": "IPY_MODEL_62e9473a81b445929a50ed73ec7a4bc0",
            "value": " 50/50 [00:18&lt;00:00,  2.80it/s, Save Time=0.00396]"
          }
        },
        "09266c6f9db14c51b15caaf120ba8e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53ebcbf3c674bffb05a2c2c6d5fb8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b23b211a494d46578512e994a75ca6f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2015359409a7460ea04a537987b57a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aee02b416d7f422db9940e19074f250a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c897976afd564098b807edf49fcfbace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e9473a81b445929a50ed73ec7a4bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18080ce320a94bd29bb91052268cd4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_649ced8701c5493e97305e5172881633",
              "IPY_MODEL_7e348b0cd16c4085b41d4e1c7a2eaf99",
              "IPY_MODEL_7d8c0e0ce916426290266cd56c9093c3"
            ],
            "layout": "IPY_MODEL_d8241a49e5d54330b78d1b89aae805c5"
          }
        },
        "649ced8701c5493e97305e5172881633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea5b5a3048d24a7fa25e6e11ab6c1fbf",
            "placeholder": "​",
            "style": "IPY_MODEL_494786afef9d44ebbb85b2062c9530ec",
            "value": "100%"
          }
        },
        "7e348b0cd16c4085b41d4e1c7a2eaf99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd33ad4b52604eff8b31ae9fc995449e",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18e51e2cfe0948288e21645bcb7c4157",
            "value": 50
          }
        },
        "7d8c0e0ce916426290266cd56c9093c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_037508a01bd44d1f8cdca41dd06e8419",
            "placeholder": "​",
            "style": "IPY_MODEL_1e3f90b24105415fbf3e7ebb61ab24ec",
            "value": " 50/50 [00:18&lt;00:00,  2.64it/s, Save Time=0.00435]"
          }
        },
        "d8241a49e5d54330b78d1b89aae805c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea5b5a3048d24a7fa25e6e11ab6c1fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494786afef9d44ebbb85b2062c9530ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd33ad4b52604eff8b31ae9fc995449e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e51e2cfe0948288e21645bcb7c4157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "037508a01bd44d1f8cdca41dd06e8419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3f90b24105415fbf3e7ebb61ab24ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61e24dfa2fee4aeb8a76d9c3d88881b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1adefd5ea78146f09200dfbd1b015068",
              "IPY_MODEL_151fbe9f752149e6b268bf328af86cfa",
              "IPY_MODEL_81150053c59d48708ea48ff2c96f91be"
            ],
            "layout": "IPY_MODEL_4cd262c4bb814db5b43dc4317c2806cb"
          }
        },
        "1adefd5ea78146f09200dfbd1b015068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03cf3f3989ec4980bb3633213b84d91e",
            "placeholder": "​",
            "style": "IPY_MODEL_d026e6ee14634de69800a911a7426613",
            "value": "100%"
          }
        },
        "151fbe9f752149e6b268bf328af86cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b414fdf05984532a953f058ca839edf",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b127edab31d945f0a3ba8f33fcc5c93f",
            "value": 50
          }
        },
        "81150053c59d48708ea48ff2c96f91be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da9f6537b0f9422c915bf310d4708639",
            "placeholder": "​",
            "style": "IPY_MODEL_711cf9b2ee344a0a9450a264d68d38c0",
            "value": " 50/50 [00:18&lt;00:00,  2.85it/s, Save Time=0.00513]"
          }
        },
        "4cd262c4bb814db5b43dc4317c2806cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03cf3f3989ec4980bb3633213b84d91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d026e6ee14634de69800a911a7426613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b414fdf05984532a953f058ca839edf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b127edab31d945f0a3ba8f33fcc5c93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da9f6537b0f9422c915bf310d4708639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711cf9b2ee344a0a9450a264d68d38c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brgsil/toxicity-lm-ia024/blob/main/PPLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "NZVBO4DrbKz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fohYb6fmorZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61533b2d-4630-4d0a-b8e5-78282b9ff39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Pipeline, GPT2Tokenizer, GPT2LMHeadModel\n",
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9c6a4f-2e48-4ea0-d823-ded670c65123",
        "id": "Zg3zHbwOorZs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.14.0-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.12.1+cu113)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.35.4-py3-none-any.whl (62.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 62.5 MB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.35.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import os\n",
        "from operator import add\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "from googleapiclient import discovery\n",
        "import time\n",
        "\n",
        "SMALL_CONST = 1e-15\n",
        "BIG_CONST = 1e10"
      ],
      "metadata": {
        "id": "-zbXGbOkorZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "   accelerator = Accelerator(mixed_precision='fp16')\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "   accelerator = Accelerator(mixed_precision='no')\n",
        "#device = torch.device(dev)\n",
        "device = accelerator.device\n",
        "print('Using {}'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b39597e-ba71-405d-b493-2cf9de3ae929",
        "id": "31NU7ZEkorZt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "nHYnHtg2orZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RTPDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, example_per_bin: int = 1000):\n",
        "\n",
        "        dataset = load_dataset('allenai/real-toxicity-prompts', split=\"train\")\n",
        "\n",
        "        bos_token = '' if 'opt' in tokenizer.name_or_path else tokenizer.bos_token\n",
        "\n",
        "        self.prompt_toxicity = np.asarray([data['prompt']['toxicity'] for data in dataset if data['prompt']['toxicity'] != None])\n",
        "        self.prompts = np.asarray([data['prompt']['text'] for data in dataset if data['prompt']['toxicity'] != None])\n",
        "        text = np.asarray([bos_token + data['prompt']['text'] for data in dataset if data['prompt']['toxicity'] != None])\n",
        "        self.challenging = np.asarray([data['challenging'] for data in dataset if data['prompt']['toxicity'] != None])\n",
        "\n",
        "        bins = np.digitize(self.prompt_toxicity, bins=np.linspace(0.1,1,10))\n",
        "\n",
        "        np.random.seed(42)\n",
        "        bins_idxs = [np.where(bins == i)[0] for i in range(10)]\n",
        "        [np.random.shuffle(arr) for arr in bins_idxs]\n",
        "        bins_idxs = np.asarray([arr[:example_per_bin] for arr in bins_idxs]).reshape(-1)\n",
        "\n",
        "        self.prompt_toxicity = self.prompt_toxicity[bins_idxs]\n",
        "        self.prompts = self.prompts[bins_idxs]\n",
        "        text = text[bins_idxs]\n",
        "        self.challenging = self.challenging[bins_idxs]\n",
        "\n",
        "        tokenizer.padding_side = 'left'\n",
        "        tokenized = tokenizer(text.tolist())\n",
        "        self.tokens = tokenized.input_ids\n",
        "        self.attentions = tokenized.attention_mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "\n",
        "    def __getitem__(self, index): \n",
        "        return self.prompts[index], self.prompt_toxicity[index], self.challenging[index], self.tokens[index], self.attentions[index]"
      ],
      "metadata": {
        "id": "O_6Ickt8orZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PPLM"
      ],
      "metadata": {
        "id": "tQ1YNrRWorZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bag_of_words_indices(tokenizer):\n",
        "    bow_indices = []\n",
        "    filepath = '/content/drive/Shareddrives/IA024-Final/toxicity_classifier/bad_words.py'\n",
        "    with open(filepath, \"r\") as f:\n",
        "        words = f.read().strip().split(\"\\n\")\n",
        "    bow_indices.append(\n",
        "        [tokenizer.encode(word.strip(),\n",
        "                            add_prefix_space=True,\n",
        "                            add_special_tokens=False)\n",
        "            for word in words])\n",
        "    return bow_indices\n",
        "\n",
        "\n",
        "def build_bows_one_hot_vectors(bow_indices, tokenizer, device='cuda'):\n",
        "    if bow_indices is None:\n",
        "        return None\n",
        "\n",
        "    one_hot_bows_vectors = []\n",
        "    for single_bow in bow_indices:\n",
        "        single_bow = list(filter(lambda x: len(x) <= 1, single_bow))\n",
        "        single_bow = torch.tensor(single_bow).to(device)\n",
        "        num_words = single_bow.shape[0]\n",
        "        one_hot_bow = torch.zeros(num_words, tokenizer.vocab_size).to(device)\n",
        "        one_hot_bow.scatter_(1, single_bow, 1)\n",
        "        one_hot_bows_vectors.append(one_hot_bow)\n",
        "    return one_hot_bows_vectors"
      ],
      "metadata": {
        "id": "B2aG5gAjorZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_filter(logits, k, probs=False):\n",
        "    \"\"\"\n",
        "    Masks everything but the k top entries as -infinity (1e10).\n",
        "    Used to mask logits such that e^-infinity -> 0 won't contribute to the\n",
        "    sum of the denominator.\n",
        "    \"\"\"\n",
        "    if k == 0:\n",
        "        return logits\n",
        "    else:\n",
        "        values = torch.topk(logits, k)[0]\n",
        "        batch_mins = values[:, -1].view(-1, 1).expand_as(logits)\n",
        "        if probs:\n",
        "            return torch.where(logits < batch_mins,\n",
        "                               torch.ones_like(logits) * 0.0, logits)\n",
        "        return torch.where(logits < batch_mins,\n",
        "                           torch.ones_like(logits) * -BIG_CONST,\n",
        "                           logits)"
      ],
      "metadata": {
        "id": "eLryDeBZorZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perturb_past(\n",
        "        past,\n",
        "        model,\n",
        "        last,\n",
        "        unpert_past=None,\n",
        "        unpert_logits=None,\n",
        "        accumulated_hidden=None,\n",
        "        grad_norms=None,\n",
        "        stepsize=0.01,\n",
        "        one_hot_bows_vectors=None,\n",
        "        num_iterations=3,\n",
        "        horizon_length=1,\n",
        "        window_length=0,\n",
        "        gamma=1.5,\n",
        "        kl_scale=0.01,\n",
        "        device='cuda'\n",
        "):\n",
        "    # Generate inital perturbed past\n",
        "    grad_accumulator = [\n",
        "        np.zeros((2, *p[0].shape)).astype(\"float32\")\n",
        "        for p in past\n",
        "    ]\n",
        "\n",
        "    if accumulated_hidden is None:\n",
        "        accumulated_hidden = 0\n",
        "\n",
        "    # TODO fix this comment (SUMANTH)\n",
        "    # Generate a mask is gradient perturbated is based on a past window\n",
        "    _, _, curr_length, _ = past[0][0].shape\n",
        "\n",
        "    # accumulate perturbations for num_iterations\n",
        "    loss_per_iter = []\n",
        "    new_accumulated_hidden = None\n",
        "    for i in range(num_iterations):\n",
        "        curr_perturbation = []\n",
        "        for p_ in grad_accumulator:\n",
        "          a = torch.from_numpy(p_[0]).float().requires_grad_(requires_grad=True).to(device)\n",
        "          a.retain_grad()\n",
        "          b = torch.from_numpy(p_[1]).float().requires_grad_(requires_grad=True).to(device)\n",
        "          b.retain_grad()\n",
        "          curr_perturbation.append((a,b))\n",
        "\n",
        "        # Compute hidden using perturbed past\n",
        "        perturbed_past = [(past[i][0] + curr_perturbation[i][0], past[i][1] + curr_perturbation[i][1]) for i in range(len(past))]\n",
        "        _, _, curr_length, _ = curr_perturbation[0][0].shape\n",
        "\n",
        "        perturbed_past = tuple(perturbed_past)\n",
        "        out = model(last, past_key_values=perturbed_past)\n",
        "        all_logits, _, all_hidden = out.logits, out.past_key_values, out.hidden_states\n",
        "        hidden = all_hidden[-1]\n",
        "        new_accumulated_hidden = accumulated_hidden + torch.sum(\n",
        "            hidden,\n",
        "            dim=1\n",
        "        ).detach()\n",
        "        # TODO: Check the layer-norm consistency of this with trained discriminator (Sumanth)\n",
        "        logits = all_logits[:, -1, :]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        loss = 0.0\n",
        "        loss_list = []\n",
        "\n",
        "        for one_hot_bow in one_hot_bows_vectors:\n",
        "                bow_logits = torch.mm(probs, torch.t(one_hot_bow))\n",
        "                bow_loss = torch.log(torch.sum(bow_logits))\n",
        "                loss += bow_loss\n",
        "                loss_list.append(bow_loss)\n",
        "\n",
        "        kl_loss = 0.0\n",
        "        if kl_scale > 0.0:\n",
        "            unpert_probs = F.softmax(unpert_logits[:, -1, :], dim=-1)\n",
        "            unpert_probs = (\n",
        "                    unpert_probs + SMALL_CONST *\n",
        "                    (unpert_probs <= SMALL_CONST).float().to(device).detach()\n",
        "            )\n",
        "            correction = SMALL_CONST * (probs <= SMALL_CONST).float().to(\n",
        "                device).detach()\n",
        "            corrected_probs = probs + correction.detach()\n",
        "            kl_loss = kl_scale * (\n",
        "                (corrected_probs * (corrected_probs / unpert_probs).log()).sum()\n",
        "            )\n",
        "            loss += kl_loss\n",
        "\n",
        "        loss_per_iter.append(loss.data.cpu().numpy())\n",
        "\n",
        "        # compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # calculate gradient norms\n",
        "        if grad_norms is not None:\n",
        "            grad_norms = [\n",
        "                torch.max(grad_norms[index], torch.norm(torch.cat((p_[0].grad.unsqueeze(0), p_[1].grad.unsqueeze(0)))))\n",
        "                for index, p_ in enumerate(curr_perturbation)\n",
        "            ]\n",
        "        else:\n",
        "            grad_norms = [\n",
        "                (torch.norm(torch.cat((p_[0].grad.unsqueeze(0), p_[1].grad.unsqueeze(0)))) + SMALL_CONST)\n",
        "                for index, p_ in enumerate(curr_perturbation)\n",
        "            ]\n",
        "\n",
        "        # normalize gradients\n",
        "        grad = [\n",
        "            -stepsize * (torch.cat((p_[0].grad.unsqueeze(0), p_[1].grad.unsqueeze(0))) / grad_norms[index] ** gamma).data.cpu().numpy()\n",
        "            for index, p_ in enumerate(curr_perturbation)\n",
        "        ]\n",
        "\n",
        "\n",
        "        # accumulate gradient\n",
        "        grad_accumulator = [grad[i] + grad_accumulator[i] for i in range(len(grad))]\n",
        "\n",
        "        # reset gradients, just to make sure\n",
        "        for p_ in curr_perturbation:\n",
        "            p_[0].grad.data.zero_()\n",
        "            p_[1].grad.data.zero_()\n",
        "\n",
        "        # removing past from the graph\n",
        "        new_past = []\n",
        "        for p_ in past:\n",
        "            new_past.append((p_[0].detach(), p_[1].detach()))\n",
        "        past = new_past\n",
        "\n",
        "    # apply the accumulated perturbations to the past\n",
        "    grad_accumulator_ = []\n",
        "    for p_ in grad_accumulator:\n",
        "        a = torch.from_numpy(p_).float().requires_grad_(requires_grad=True).to(device)\n",
        "        a.retain_grad()\n",
        "        grad_accumulator_.append(a)\n",
        "    grad_accumulator = grad_accumulator_\n",
        "\n",
        "    pert_past = [(past[i][0] + grad_accumulator[i][0], past[i][1] + grad_accumulator[i][1]) for i in range(len(past))]\n",
        "\n",
        "    return pert_past, grad_norms"
      ],
      "metadata": {
        "id": "xS9YC4JworZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model,\n",
        "              context,\n",
        "              perturb=True,\n",
        "              length=10,\n",
        "              stepsize=0.02,\n",
        "              temperature=1.0,\n",
        "              top_k=10,\n",
        "              sample=True,\n",
        "              num_iterations=10,\n",
        "              grad_length=10000,\n",
        "              horizon_length=1,\n",
        "              window_length=0,\n",
        "              gamma=1.0,\n",
        "              gm_scale=0.9,\n",
        "              kl_scale=0.01):\n",
        "  \n",
        "    output_so_far = torch.tensor([context]).to(device)\n",
        "\n",
        "    bow_indices = get_bag_of_words_indices(tokenizer)\n",
        "    one_hot_bows_vectors = build_bows_one_hot_vectors(bow_indices, tokenizer, device)\n",
        "\n",
        "    grad_norms = None\n",
        "    last = None\n",
        "    past = None\n",
        "\n",
        "    for i in range(length):\n",
        "\n",
        "        # Get past/probs for current output, except for last word\n",
        "        # Note that GPT takes 2 inputs: past + current_token\n",
        "\n",
        "        # run model forward to obtain unperturbed\n",
        "        if past is None and output_so_far is not None:\n",
        "            last = output_so_far[:, -1:]\n",
        "            if output_so_far.shape[1] > 1:\n",
        "                out = model(output_so_far[:, :-1])\n",
        "                _, past, _ = out.logits, out.past_key_values, out.hidden_states\n",
        "                #past = [torch.cat((layer[0], layer[1])).reshape(len(past[0]), *past[0][0].shape) for layer in past]\n",
        "\n",
        "        out = model(output_so_far)\n",
        "        unpert_logits, unpert_past, unpert_all_hidden = out.logits, out.past_key_values, out.hidden_states\n",
        "        #unpert_past = [torch.cat((layer[0], layer[1])).reshape(len(unpert_past[0]), *unpert_past[0][0].shape) for layer in unpert_past]\n",
        "        unpert_last_hidden = unpert_all_hidden[-1]\n",
        "\n",
        "        # check if we are abowe grad max length\n",
        "        if i >= grad_length:\n",
        "            current_stepsize = stepsize * 0\n",
        "        else:\n",
        "            current_stepsize = stepsize\n",
        "\n",
        "        # modify the past \n",
        "        accumulated_hidden = unpert_last_hidden[:, :-1, :]\n",
        "        accumulated_hidden = torch.sum(accumulated_hidden, dim=1)\n",
        "\n",
        "        if past is not None:\n",
        "            pert_past, grad_norms = perturb_past(\n",
        "                past,\n",
        "                model,\n",
        "                last,\n",
        "                unpert_past=unpert_past,\n",
        "                unpert_logits=unpert_logits,\n",
        "                accumulated_hidden=accumulated_hidden,\n",
        "                grad_norms=grad_norms,\n",
        "                stepsize=current_stepsize,\n",
        "                one_hot_bows_vectors=one_hot_bows_vectors,\n",
        "                num_iterations=num_iterations,\n",
        "                horizon_length=horizon_length,\n",
        "                window_length=window_length,\n",
        "                gamma=gamma,\n",
        "                kl_scale=kl_scale,\n",
        "                device=device\n",
        "            )\n",
        "        else:\n",
        "            pert_past = past\n",
        "\n",
        "        pert_past = tuple([(layer[0], layer[1]) for layer in pert_past])\n",
        "        out = model(last, past_key_values=pert_past)\n",
        "        pert_logits, past, pert_all_hidden = out.logits, out.past_key_values, out.hidden_states\n",
        "        #past = [torch.cat((layer[0], layer[1])).reshape(len(past[0]), *past[0][0].shape) for layer in past]\n",
        "        pert_logits = pert_logits[:, -1, :] / temperature  # + SMALL_CONST\n",
        "        pert_probs = F.softmax(pert_logits, dim=-1)\n",
        "\n",
        "        # Fuse the modified model and original model\n",
        "\n",
        "        unpert_probs = F.softmax(unpert_logits[:, -1, :], dim=-1)\n",
        "\n",
        "        pert_probs = ((pert_probs ** gm_scale) * (\n",
        "                unpert_probs ** (1 - gm_scale)))  # + SMALL_CONST\n",
        "        pert_probs = top_k_filter(pert_probs, k=top_k,\n",
        "                                    probs=True)  # + SMALL_CONST\n",
        "\n",
        "        # rescale\n",
        "        pert_probs = pert_probs / torch.sum(pert_probs, dim=-1).unsqueeze(1)\n",
        "\n",
        "        # sample or greedy\n",
        "        if sample:\n",
        "            last = torch.multinomial(pert_probs, num_samples=1)\n",
        "\n",
        "        else:\n",
        "            _, last = torch.topk(pert_probs, k=1, dim=-1)\n",
        "\n",
        "        # update context/output_so_far appending the new token\n",
        "        output_so_far = (\n",
        "            last if output_so_far is None\n",
        "            else torch.cat((output_so_far, last), dim=1)\n",
        "        )\n",
        "\n",
        "    return output_so_far"
      ],
      "metadata": {
        "id": "7O558yrOorZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_generations = 5\n",
        "test_models = [\"EleutherAI/gpt-neo-125M\",\n",
        "               \"EleutherAI/gpt-neo-1.3B\",\n",
        "              #  #\"EleutherAI/gpt-neo-2.7B\",\n",
        "               \"gpt2\",\n",
        "               \"gpt2-medium\",\n",
        "               \"gpt2-large\",\n",
        "               \"gpt2-xl\",\n",
        "               \"facebook/opt-125m\",\n",
        "               \"facebook/opt-350m\",\n",
        "               \"facebook/opt-1.3b\",\n",
        "              #  \"facebook/opt-2.7b\",\n",
        "            #    \"facebook/opt-6.7b\",\n",
        "               \"facebook/galactica-125m\",\n",
        "               \"facebook/galactica-1.3b\",\n",
        "               #\"facebook/galactica-6.7b\",\n",
        "               \"bigscience/bloom-560m\",\n",
        "               \"bigscience/bloom-1b1\",\n",
        "               \"bigscience/bloom-1b7\",\n",
        "            #    \"bigscience/bloom-3b\",\n",
        "            #    \"bigscience/bloom-7b1\"\n",
        "               ]"
      ],
      "metadata": {
        "id": "qemQpKIoorZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in test_models:\n",
        "    \n",
        "    save_path = '/content/drive/Shareddrives/IA024-Final/PPLM/RTP/' + model_name.replace('/','_') + '.json'\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "        if tokenizer.pad_token is None:\n",
        "            if 'galactica' in model_name:\n",
        "                tokenizer.bos_token_id = 0\n",
        "                tokenizer.pad_token_id = 1\n",
        "                tokenizer.eos_token_id = 2\n",
        "                tokenizer.unk_token_id = 3\n",
        "            else:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "                \n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name, \n",
        "                                                     use_cache=True,\n",
        "                                                     output_hidden_states=True,\n",
        "                                                     device_map=\"auto\", \n",
        "                                                     cache_dir=\"/content/drive/Shareddrives/IA024-Final/models\")\n",
        "        model.eval()\n",
        "\n",
        "        dataset = RTPDataset(tokenizer, example_per_bin=5)\n",
        "\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        generated_outputs = []\n",
        "\n",
        "        pbar = tqdm(dataset, total=len(dataset))\n",
        "        for prompt, toxicity, challenge, input, mask in pbar:\n",
        "            gen_texts = []\n",
        "            for i in range(num_generations):\n",
        "                gen = generate(model, input, length=20)\n",
        "                gen_texts.append(tokenizer.decode(gen[0, len(input):], skip_special_tokens=True))\n",
        "            \n",
        "            output = {'prompt': prompt,\n",
        "                    'toxicity': toxicity,\n",
        "                    'challenging': str(challenge),\n",
        "                    'model_generated': gen_texts}\n",
        "            generated_outputs.append(output)\n",
        "            \n",
        "        with open(save_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(generated_outputs, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972,
          "referenced_widgets": [
            "fe7e9b182c2443bd8e2da77e3a4beedd",
            "776001528eb2452798cc94f58e8e709a",
            "8dca820abe87453c81a9aadb5f1867ce",
            "f7037dc26af44f00822ba847cd50c592",
            "d3cb47c47dae42a086a57786b8d01f49",
            "454f501eae4f46cfa99a2b7c6c7e4d50",
            "16f980e73eaa4ab4b307580655c74caf",
            "ea075423f3a64c68a63c8fd7f5ecbac2",
            "e3bb989de7344baeac941a151925ee78",
            "b22b71d2113c403a9b00c20f46a3e370",
            "7ba6b8dc428b45b0845c6e46ebeacb8a",
            "3bf251ed67a04b8da815e79e5e612739",
            "ac88b682985445c29e28fc6be5e6cc1f",
            "e376456072fd4f96b2d21c5f5c3de1d1",
            "dfad6d5601e24bb796344e3e903b0d9e",
            "032adccf0759441e846d3599aa6213f8",
            "57ba1128b666453e9399996128829c59",
            "59607e287132496dad04b4567212102d",
            "0b9e7e870ebc407582c2e7e7c114659c",
            "88b02190aeab4df3bc27a4b16a963630",
            "09577bf7bf2543f4a8fa97f762c030c5",
            "45187f4d68754e1aa83c4688aaec47ee",
            "ca04d00248b8400b966571c94aa1b252",
            "e24c1ebe01424c14a27193b3a29bec00",
            "f5c056d6782b45e5a122d7b3915bc531",
            "a7a38b76443f4872be696a59ef43dbda",
            "75664d4409244ac2a1f54fc6357bcac4",
            "eade0ac431f14043a377d6e6e11b1c86",
            "d0a06bd8e6a84ac98639ae244b679738",
            "1844fbe899a841dfa442e7c65188ef2b",
            "4a94356641d04d35945bc86bbcbae172",
            "40b58f842a4c42f3a76f8a42cedb2bae",
            "b3d38bec3eb246249782ef407002c0a9",
            "fd7a76499b2b4782add28c232309c574",
            "9521f577758e4546ab54b6fe034ab7e2",
            "432b0ab7fe2247cda95c53c8b4d6b37c",
            "8f96a2f99d064a22a8e9a348a2943e0c",
            "bf1e47732b244f5d8d798b82e632a610",
            "b7746b6837e247d7aaf394686e7a3d62",
            "e42ae6456f0f492e95dad7462ae86e5e",
            "d867e3de5d1647b8b372e79d09b1e19c",
            "67df23360cad4debb5dd600c01ceda7d",
            "c5d6abc483b54b6383cd49d58273c164",
            "07d8f5be41ad4f24bde2094926ce2fd9",
            "77a0ad27a89b433191039d4097d606cf",
            "3ab720d45f3043bd92ecba230e1b33d6",
            "d08429aece6b4b7ea4cf08bf23338430",
            "835fb211e160491d91d2869f73c1b734",
            "4d567a2086a84d06883fcb936add4d4a",
            "3b7503d4b9a44fc19e521937bae01288",
            "8022a9e81ef84a35ab4b8f07f57b855f",
            "934fe46fec5b4bc2b394750f9efd0621",
            "31c8820ca29e417fae5a161ea8ee64e6",
            "5a483a19bff64a7e83519437f2b7b1bb",
            "39ba8e657b7447e39d7b83cbb5376c9e",
            "a30aec455ac74856a5915524d27fa59d",
            "40005770026243fc9dc4ea35efc31461",
            "6ee7647d167046798d8125f7260f3927",
            "bfdaa86113a14b9bb45a47b873e3dcdf",
            "fce87399617f47baae1fb9e9db3ab146",
            "94992a0ee9d34229aa629f7065278f4f",
            "e121831610dd4f96b4bb7e971383d415",
            "318afbbeef1f441abd2ad1cf25cbb0d8",
            "dfb8d29c69f9482c84d58d44fbd4c817",
            "8d86f7c1fb5a40e9a54a80683c50df0b",
            "7ca7122f72be4876b483924a72017108",
            "a6f12383e92f471384f34b61cba11db7",
            "aeb2fbf614a54ab3886538c251eb6326",
            "fe41111abaa646cba8f9de89166f2917",
            "9e1374031c34491894311060904bf51d",
            "51f21b0d560d4b2aaa519b00e7b6c8c1",
            "db90b42405f54ba6991d7c0d24894b7a",
            "dd6672920e0b43379b62e834b7fa44b4",
            "ea8568d27e0b453fb1382beea51667e2",
            "7702280037ac406abdc50078b1491854",
            "69987159ab514282be7f0ae0d644df15",
            "8712599b0bb14c0cb40ffe86497aa68d",
            "dc175cdce2c54627aafb6dbc011f2aa3",
            "d4818f2a7c244f5ba10806fd7355da50",
            "b8c02c8e91f74a2385c178aa9ba55c71",
            "2a879bfc426e4a2f925ed3f0c9c01374",
            "8246c7aa3a754d65be6828ff83b64774",
            "add097a2e76f4a3dae8ab6b69f057735",
            "4526f7f2dbc240d99f65f6ddf901d7dd",
            "0aa0f2cd58b04dc0a701c9fd68543ad6",
            "38c876b02af3494cb5bc13785215e2f0",
            "6331cf52398949f4a95a23b3285a483e",
            "f404063ad6f44c79a3a5f59352ea5b07",
            "38c5b88665e14fc1aa84760bcb6b7a7a",
            "26325c0cf2b14a64b0cd3543cdab40e8",
            "340dbaa68eb347079a3650fce2b22169",
            "b4ea07b577674141a71f5733d2a29306",
            "caaf660255734b4799574982c4cbf44b",
            "091e330f170a4391b7e5fe03c12414c4",
            "214188f05a96464199dad45f3059b401",
            "6b3efc332f184d509174f15b38905232",
            "e5a9e9c060d448f4adfd992b759efe7b",
            "6daecb3ae2574d258b6ed03cf9e2ff5e",
            "e1dd765dae664da3917aa9d64f68ad3f",
            "d679829b7c8f46e1b1b16c0e6e4c97c2",
            "0f135e84a5664b1091f71010efbc4c25",
            "2bf0b85c4e504f46ba30723380f6ccdb",
            "104115426b6942879c6f6a8a5d0f1a83",
            "1387d6bb8de047e4b468885f043ff2d8",
            "baf4463f4eb2443eb14e6697ab4fe14a",
            "f9c71bcdb039490c93835e5f86f138b0",
            "db9feafec31a443a8e09f31236b54f96",
            "f49b1a6c12e0410686e0559f8904aabb",
            "367b88e7acbe4313b7b9f4ea3cbe52e6",
            "99dfb5323b174ca7bbc4a8624cf5c1ea",
            "e9abe6f32e474b57bbda15fc736532ba",
            "74990510270141bc83ed391bb0b2fecb",
            "c0f643ce470e4a778047a8829efadbe0",
            "81ac999ea80b4d5daed38fa51c61a992",
            "fc21a31151da419eb75ec2a3e8738b67",
            "f1ceb505340b42519f55532201a7f28a",
            "d83ad9a17c1245d69e59e7d3715e6b84",
            "2e5db116aef34b0ebd4d4df560573fb7",
            "b35867d363434574b2fc1d5815ae61af",
            "69486a2214b74bf58727952652eb67b7",
            "c3844348c1b74acfb4f888f2395d1984",
            "e5b511094adf44ac934d4a24fd2bb343",
            "4e65c7ef449149d6b1a819ae4967a161",
            "64a893e63f9e4a4fa550b68a7739a9bd",
            "298c1a2e37ec4470988f00ba0aa97d28",
            "323143ab0d6941c89b4f7b25319cc94d",
            "36cdbd7b25dd4dc788fc722429352e42",
            "9a7255996ad74871babe3007695892b0",
            "00212b1d7edd4e93b79860ec9056b910",
            "6b8454db90794bcea5aeb918560dedd3",
            "ce5c32ce62e44f748cb39bf4ea5cf5b1",
            "c8e86577f77542f9ad95373dd5c2f5cc",
            "5a4189fbd2424140b1c70523c937ac90",
            "7d0123b7085c44c88f12acd3bf2bf650",
            "8299745220f94911b6960c6b8f751199",
            "c2ca3ef1abe842429d02df17ecfe5ea7",
            "1892e3471ef246858c0a242341ff5b4e",
            "c4fa1b3ac6134f28a32c35dd51552551",
            "87b6eb48914243bf94861027bf62cf73",
            "9e7f295620c64ec684f0e4cb2db035db",
            "7888bd2f970e48b3a60aa667f7e70fcf",
            "f5a101ddbf074cc5b361a9dcce254ef3",
            "82b026755d5a46ca9e1bc5a3fdef10db"
          ]
        },
        "id": "G2T1GUCOorZy",
        "outputId": "4e05416f-d926-4c9d-e5e8-146c0c812915"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using pad_token, but it is not set yet.\n",
            "WARNING:datasets.builder:Using custom data configuration allenai--real-toxicity-prompts-d8a476abeeb3bf44\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-d8a476abeeb3bf44/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe7e9b182c2443bd8e2da77e3a4beedd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bf251ed67a04b8da815e79e5e612739",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca04d00248b8400b966571c94aa1b252",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd7a76499b2b4782add28c232309c574",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77a0ad27a89b433191039d4097d606cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a30aec455ac74856a5915524d27fa59d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration allenai--real-toxicity-prompts-d8a476abeeb3bf44\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-d8a476abeeb3bf44/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6f12383e92f471384f34b61cba11db7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc175cdce2c54627aafb6dbc011f2aa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38c5b88665e14fc1aa84760bcb6b7a7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d679829b7c8f46e1b1b16c0e6e4c97c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9abe6f32e474b57bbda15fc736532ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5b511094adf44ac934d4a24fd2bb343"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration allenai--real-toxicity-prompts-d8a476abeeb3bf44\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-d8a476abeeb3bf44/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a4189fbd2424140b1c70523c937ac90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0905065955d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mgen_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mgen_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-acddf884c7dd>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(model, context, perturb, length, stepsize, temperature, top_k, sample, num_iterations, grad_length, horizon_length, window_length, gamma, gm_scale, kl_scale)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mkl_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkl_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             )\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-46bfd14e8175>\u001b[0m in \u001b[0;36mperturb_past\u001b[0;34m(past, model, last, unpert_past, unpert_logits, accumulated_hidden, grad_norms, stepsize, one_hot_bows_vectors, num_iterations, horizon_length, window_length, gamma, kl_scale, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mperturbed_past\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_past\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperturbed_past\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mall_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m         )\n\u001b[1;32m   1061\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                 )\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_buffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffload_buffers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_submodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             ):\n\u001b[0;32m--> 264\u001b[0;31m                 \u001b[0mset_module_tensor_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in test_models:\n",
        "    \n",
        "    load_path = '/content/drive/Shareddrives/IA024-Final/PPLM/RTP/' + model_name.replace('/','_') + '.json'\n",
        "    save_path = '/content/drive/Shareddrives/IA024-Final/PPLM/RTP/' + model_name.replace('/','_') + '_scored' + '.json'\n",
        "\n",
        "    if os.path.exists(load_path):\n",
        "\n",
        "        with open(load_path, 'r') as f:\n",
        "            gen_data = json.load(f)\n",
        "    \n",
        "\n",
        "        API_KEY = 'AIzaSyAUAPSOGpv4ZfqaIkuqHCOdABmR0fL0upA'\n",
        "\n",
        "        client = discovery.build(\n",
        "            \"commentanalyzer\",\n",
        "            \"v1alpha1\",\n",
        "            developerKey=API_KEY,\n",
        "            discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\"\n",
        "        )\n",
        "\n",
        "        scored_data = []\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r') as f:\n",
        "                scored_data = json.load(f)\n",
        "        \n",
        "        pbar = tqdm(range(len(scored_data), len(gen_data)), total=len(gen_data)-len(scored_data))\n",
        "        for data_idx in pbar:\n",
        "            data = gen_data[data_idx]\n",
        "            data['scores'] = []\n",
        "            for sample in data['model_generated']:\n",
        "                if sample != '':\n",
        "                    analyze_request = {\n",
        "                    'comment': { 'text': sample },\n",
        "                    'requestedAttributes': {'TOXICITY': {}},\n",
        "                    'languages': ['en']\n",
        "                    }\n",
        "\n",
        "                    toxicity_value = -1\n",
        "                    while toxicity_value == -1:\n",
        "                        try:\n",
        "                            response = client.comments().analyze(body=analyze_request).execute()\n",
        "                            toxicity_value = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
        "                        except Exception as err:\n",
        "                            #print(err)\n",
        "                            time.sleep(1) # Wait for more quota\n",
        "                else:\n",
        "                    toxicity_value = 0\n",
        "\n",
        "                data['scores'].append(toxicity_value)\n",
        "            \n",
        "            scored_data.append(data)\n",
        "\n",
        "            # Save checkpoint of processed data\n",
        "            if data_idx % 100 == 0:\n",
        "                start_save_time = time.perf_counter()\n",
        "                with open(save_path, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(scored_data, f, ensure_ascii=False, indent=4)\n",
        "                pbar.set_postfix({'Save Time': time.perf_counter() - start_save_time})\n",
        "        \n",
        "        with open(save_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(scored_data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "d112fa02f5c043dbad43719875b3c062",
            "011ad6dd845548388bb76c3fd974060c",
            "7a0e60576f844f5492726c605fcfb7da",
            "9d4b78a0e4b944208f1607c4aff5b2a2",
            "2e9c30d6945e45da89f2c6a18e7981ba",
            "1bf96fd2359747318f256775b7e4d43a",
            "7e64e6581e1b4e95a6e4219d6eba6c49",
            "8dc57ccb43b74418945528774860471f",
            "3663b7c172094c4f9982909718631f86",
            "a4b1f67058e54407ae80d9ab054c2971",
            "928841920bcb4796a8db48a02ffe74e3",
            "793da7d00b934211b0a9e3ebf838f4a8",
            "ab81245a6d41463eb136c1bec5685ecf",
            "61d8f5bf131a480d91eb45595529941f",
            "e71ee40d8d4c4407bd28edaa9462d0a7",
            "09266c6f9db14c51b15caaf120ba8e6d",
            "e53ebcbf3c674bffb05a2c2c6d5fb8f6",
            "b23b211a494d46578512e994a75ca6f7",
            "2015359409a7460ea04a537987b57a44",
            "aee02b416d7f422db9940e19074f250a",
            "c897976afd564098b807edf49fcfbace",
            "62e9473a81b445929a50ed73ec7a4bc0",
            "18080ce320a94bd29bb91052268cd4cf",
            "649ced8701c5493e97305e5172881633",
            "7e348b0cd16c4085b41d4e1c7a2eaf99",
            "7d8c0e0ce916426290266cd56c9093c3",
            "d8241a49e5d54330b78d1b89aae805c5",
            "ea5b5a3048d24a7fa25e6e11ab6c1fbf",
            "494786afef9d44ebbb85b2062c9530ec",
            "cd33ad4b52604eff8b31ae9fc995449e",
            "18e51e2cfe0948288e21645bcb7c4157",
            "037508a01bd44d1f8cdca41dd06e8419",
            "1e3f90b24105415fbf3e7ebb61ab24ec",
            "61e24dfa2fee4aeb8a76d9c3d88881b0",
            "1adefd5ea78146f09200dfbd1b015068",
            "151fbe9f752149e6b268bf328af86cfa",
            "81150053c59d48708ea48ff2c96f91be",
            "4cd262c4bb814db5b43dc4317c2806cb",
            "03cf3f3989ec4980bb3633213b84d91e",
            "d026e6ee14634de69800a911a7426613",
            "6b414fdf05984532a953f058ca839edf",
            "b127edab31d945f0a3ba8f33fcc5c93f",
            "da9f6537b0f9422c915bf310d4708639",
            "711cf9b2ee344a0a9450a264d68d38c0"
          ]
        },
        "id": "yrhggxePgcDf",
        "outputId": "96d8303c-763a-450b-efb7-ab5df7b66ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d112fa02f5c043dbad43719875b3c062"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "793da7d00b934211b0a9e3ebf838f4a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18080ce320a94bd29bb91052268cd4cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61e24dfa2fee4aeb8a76d9c3d88881b0"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}